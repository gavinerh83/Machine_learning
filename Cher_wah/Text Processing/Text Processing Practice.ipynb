{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c050e3",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd94391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4123abe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b874ee",
   "metadata": {},
   "source": [
    "### Input paragraph of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e094b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''\n",
    "I want white teeth.\n",
    "In England, TJ Maxx is called TK Maxx.\n",
    "Tom can't forget the time he and Mary had their first argument.\n",
    "This is the biggest bookstore in town.\n",
    "You have a big stain on your pullover.\n",
    "I will never forget that day.\n",
    "The plant was fake but looked very real.\n",
    "My sister just got home.\n",
    "Let's hang out soon.\n",
    "I am not very fond of the way you treat people.\n",
    "I opened the door.\n",
    "Tinder works.\n",
    "There’s a good chance it’ll rain tomorrow.\n",
    "He is my father.\n",
    "I want to ask them when their big day is.\n",
    "I'm sure he meant to do that.\n",
    "That's all!\n",
    "She waited until the elevator was full to clear her throat and say, “You guys might be wondering why I called this meeting.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a29121",
   "metadata": {},
   "source": [
    "### Use the functions in NLTK to separate the paragraph into sentences and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ce513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5bbcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nI want white teeth.',\n",
       " 'In England, TJ Maxx is called TK Maxx.',\n",
       " \"Tom can't forget the time he and Mary had their first argument.\",\n",
       " 'This is the biggest bookstore in town.',\n",
       " 'You have a big stain on your pullover.',\n",
       " 'I will never forget that day.',\n",
       " 'The plant was fake but looked very real.',\n",
       " 'My sister just got home.',\n",
       " \"Let's hang out soon.\",\n",
       " 'I am not very fond of the way you treat people.',\n",
       " 'I opened the door.',\n",
       " 'Tinder works.',\n",
       " 'There’s a good chance it’ll rain tomorrow.',\n",
       " 'He is my father.',\n",
       " 'I want to ask them when their big day is.',\n",
       " \"I'm sure he meant to do that.\",\n",
       " \"That's all!\",\n",
       " 'She waited until the elevator was full to clear her throat and say, “You guys might be wondering why I called this meeting.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd688ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5494788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f7dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98b8a6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f2a2a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'want', 'white']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d62e789",
   "metadata": {},
   "source": [
    "### Introduction to Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9694f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36beafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f186231",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27d6b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words] # creating a list of stemmed words\n",
    "    sentences[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e186cecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I want white teeth .',\n",
       " 'In england , TJ maxx is call TK maxx .',\n",
       " \"tom ca n't forget the time he and mari had their first argument .\",\n",
       " 'thi is the biggest bookstor in town .',\n",
       " 'you have a big stain on your pullov .',\n",
       " 'I will never forget that day .',\n",
       " 'the plant wa fake but look veri real .',\n",
       " 'My sister just got home .',\n",
       " \"let 's hang out soon .\",\n",
       " 'I am not veri fond of the way you treat peopl .',\n",
       " 'I open the door .',\n",
       " 'tinder work .',\n",
       " 'there ’ s a good chanc it ’ ll rain tomorrow .',\n",
       " 'He is my father .',\n",
       " 'I want to ask them when their big day is .',\n",
       " \"I 'm sure he meant to do that .\",\n",
       " \"that 's all !\",\n",
       " 'she wait until the elev wa full to clear her throat and say , “ you guy might be wonder whi I call thi meet .']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1070295",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d42231e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "010c2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33ac7262",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = nltk.sent_tokenize(paragraph)\n",
    "for i in range(len(sentence2)):\n",
    "    words = nltk.word_tokenize(sentence2[i])\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    sentence2[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d193ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I want white teeth .',\n",
       " 'In England , TJ Maxx is called TK Maxx .',\n",
       " \"Tom ca n't forget the time he and Mary had their first argument .\",\n",
       " 'This is the biggest bookstore in town .',\n",
       " 'You have a big stain on your pullover .',\n",
       " 'I will never forget that day .',\n",
       " 'The plant wa fake but looked very real .',\n",
       " 'My sister just got home .',\n",
       " \"Let 's hang out soon .\",\n",
       " 'I am not very fond of the way you treat people .',\n",
       " 'I opened the door .',\n",
       " 'Tinder work .',\n",
       " 'There ’ s a good chance it ’ ll rain tomorrow .',\n",
       " 'He is my father .',\n",
       " 'I want to ask them when their big day is .',\n",
       " \"I 'm sure he meant to do that .\",\n",
       " \"That 's all !\",\n",
       " 'She waited until the elevator wa full to clear her throat and say , “ You guy might be wondering why I called this meeting .']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ca0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
